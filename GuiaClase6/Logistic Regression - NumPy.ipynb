{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6cW6Tt71ik7"
      },
      "source": [
        "# Logistic Regression - NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow8ElyEq1ilG"
      },
      "source": [
        "El objetivo de éste ejercicio es que implementen paso a paso los building blocks del modelo de regresión logística, para finalmente crear una clase del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-OtSR4S1ilI"
      },
      "source": [
        "## Cargamos las Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GelzAxhl1ilK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c1yUsFQ1ilM"
      },
      "source": [
        "## Implementación de Building Blocks del Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH4ZrYLq1ilN"
      },
      "source": [
        "A continuación, se deberán implementar paso a paso los distintos bloques de código que conforman el modelo, junto con algunas funciones auxiliares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cQ5HGjo1ilO"
      },
      "source": [
        "### Función Sigmoid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKEkY5Mu1ilQ"
      },
      "source": [
        "Implementar la función: $g(z) = \\frac{1}{1 + e^{-z}}$ en NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYVpVyGC1ilR"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqEUZVI71ilT"
      },
      "source": [
        "### Binary Cross Entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GidRCnI1ilV"
      },
      "source": [
        "Implementar la función de costo: $J(w) = \\frac{1}{n}\\sum_{i=1}^{n}L\\left ( \\hat{y},y \\right )= \\frac{1}{n}\\sum_{i=1}^{n}\\left [y^{(i)}log(\\hat{y}^{(i)})+ (1-y^{(i)})log(1-\\hat{y}^{(i)}) \\right ]$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHlcXFNo1ilX"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "def loss(y_true, y_pred):\n",
        "  return np.mean(y_true*np.log(y_pred)+(1-y_true)*np.log(1-y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2RAJs641ilY"
      },
      "source": [
        "### Gradiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0SOON501ilZ"
      },
      "source": [
        "Implementar el gradiente de la función costo respecto de los parámetros: $\\frac{\\partial J(w)}{\\partial w} = \\frac{1}{n}\\sum_{i=1}^{n}\\left ( \\hat{y}^{i}-y^{i}\\right )\\bar{x}^i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZaUg5z_1ila"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "def grad_loss(y_true, y_pred, x):\n",
        "  return np.mean((y_pred-y_true)*x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfARfXhh1ilb"
      },
      "source": [
        "### Normalización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqeHqr_O1ilb"
      },
      "source": [
        "Implementar normalización Z-score de las features de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUI3pmp-1ilc"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "def z_score(x):\n",
        "  return (x-np.mean(x))/np.var(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLQerv2U1ilc"
      },
      "source": [
        "### Métricas (Precision, Recall y Accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA3vrBcv1ild"
      },
      "source": [
        "Implementar las métricas en NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYQEugfr1ile"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "def metricas(y_pred, y_true):\n",
        "  Tr = np.array(x)\n",
        "  Pr = np.array(y)\n",
        "  TP = np.size(np.where(Pr+Tr==0)) #sum(Tr & Pr)\n",
        "  TN = np.size(np.where(Pr+Tr==2))\n",
        "  FN = np.size(np.intersect1d(np.where(Pr+Tr==1),np.where(Tr)))\n",
        "  FP = np.size(np.intersect1d(np.where(Pr+Tr==1),np.where(Pr)))\n",
        "    \n",
        "  P = TP/(TP+FP) #Precision\n",
        "  R = TP/(TP+FN) #Recall\n",
        "  A = (TP+TN)/(TP+TN+FN+FP) #Accuracy\n",
        "    \n",
        "  return P, R, A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsf3-jQM1ile"
      },
      "source": [
        "### Implementar función fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhnP6Uvc1ilf"
      },
      "source": [
        "Utilizas los bloques anteriores, junto con la implementación en NumPy del algoritmo Mini-Batch gradient descent, para crear la función fit de nuestro modelo de regresión logística. Cada un determinado número de epochs calculen el loss, almacénenlo en una lista y hagan un log de los valores. La función debe devolver los parámetros ajustados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6syf61c1ilf"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "def fit(self, X, y, lr, b, epochs, bias=True):\n",
        "    # si decidimos utilizar bias, agregamos como siempre una columna con '1' al dataset de entrada\n",
        "    if bias:\n",
        "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "\n",
        "    # inicializamos aleatoriamente los pesos\n",
        "    w = np.random.rand(len(X))\n",
        "    \n",
        "    loss_list = []\n",
        "\n",
        "    # corremos Mini-Batch para optimizar los parámetros\n",
        "    for j in range(epochs)\n",
        "        idx = np.random.permutation(X.shape[0])\n",
        "        X_train = X[idx]\n",
        "        y_train = y[idx]\n",
        "        batch_size = int(len(X_train)/b)\n",
        "\n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            # Seleccionar los elementos del batch actual\n",
        "            end = #notimplemented\n",
        "            batch_X = X_train[i: end]\n",
        "            batch_y = y_train[i: end]\n",
        "\n",
        "            # cálculo de predicciones\n",
        "            prediction = #...\n",
        "            # cálculo del error\n",
        "            error = prediction.reshape(-1, 1) - batch_y.reshape(-1, 1)\n",
        "            # cálculo del grandiente\n",
        "            grad_sum = np.sum(error * batch_X, axis=0)\n",
        "            grad_mul = 1 / batch_size * grad_sum\n",
        "            gradient = np.transpose(grad_mul).reshape(-1, 1)\n",
        "            #actualizar pesos\n",
        "            W = #...\n",
        "    #self.model = W\n",
        "    return NotImplemented"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO6A0wsV1ilh"
      },
      "source": [
        "### Implementar función predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUa2g6S91ilh"
      },
      "source": [
        "Implementar la función predict usando los parámetros calculados y la función sigmoid. Prestar atención a las transformaciones de los datos de entrada. Asimismo, se debe tomar una decisión respecto de los valores de salida como: $p\\geq 0.5 \\to 1, p<0.5 \\to 0$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08WKPBHQ1ili"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "def predict(self, X):\n",
        "    return NotImplemented"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1294bnv1ili"
      },
      "source": [
        "## Armar una clase LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6-GHsqN1ilj"
      },
      "source": [
        "Armar una clase LogisticRegression que herede de BaseModel y tenga la siguiente estructura:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z03pQKSu1ilk"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(BaseModel):\n",
        "    \n",
        "    def sigmoid(self, x):\n",
        "        return NotImplemented\n",
        "\n",
        "    def fit(self, X, y, lr, b, epochs, bias=True):\n",
        "        \n",
        "        return NotImplemented\n",
        "        \n",
        "    def predict(self, X):\n",
        "        return NotImplemented"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YKjIFRg1ill"
      },
      "source": [
        "## Testear con Datasets sintéticos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY5gBif41ill"
      },
      "source": [
        "La librería Scikit-Learn tiene una función make_classification que nos permite armar datasets de prueba para problemas de clasificación. Prueben con datasets que tengan varios clusters por clase, que tengan menor o mayor separación y calculen las métricas en cada caso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjHJSZeY1iln"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "# X, y = make_classification(n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Logistic Regression - NumPy.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}