{"cells":[{"cell_type":"markdown","metadata":{"id":"CCV9e2v6KNb4"},"source":["# Implementación de PCA en NumPy"]},{"cell_type":"markdown","metadata":{"id":"ndxLg44tKNb9"},"source":["## Objetivos\n","* Implementación de PCA en NumPy paso a paso\n","* Comparación de resultados con Scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"YTsHeKntKNb-"},"source":["## Implementación"]},{"cell_type":"markdown","metadata":{"id":"eoCfAUDhKNb_"},"source":["1. Dado un dataset $X \\in \\mathbb{R}^{n, d}$, con $n$ muestras y $d$ features, queremos reducir sus dimensiones a $m$. Para ello, el primer paso es centrar el dataset (Hint: usen np.mean)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M0oivAsTKNb_","executionInfo":{"status":"ok","timestamp":1650921860369,"user_tz":180,"elapsed":22,"user":{"displayName":"Benjamin Alfredo Tourn","userId":"09466237909255247827"}},"outputId":"6d85cdea-6808-44be-f3ae-6eb9f5911bf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.34759055 -0.3745529   0.42449536  0.33557101]\n"," [ 0.11197924  0.19324905  0.30862306 -0.32827205]\n"," [-0.47216811 -0.28214419  0.07339552 -0.3548591 ]\n"," [ 0.4078188  -0.47912197 -0.35072809  0.40975087]\n"," [-0.28047819  0.2715794  -0.31194541 -0.12194819]\n"," [-0.0529189   0.03255979 -0.12219418  0.3493451 ]\n"," [-0.15741205  0.16120371 -0.10748035  0.17579962]\n"," [ 0.33317702  0.35885584 -0.04978823 -0.40612752]\n"," [-0.19685529  0.3747698   0.46248926 -0.03001922]\n"," [-0.04073306 -0.25639853 -0.32686693 -0.02924053]]\n"]}],"source":["# INSERTAR CÓDIGO AQUÍ\n","import numpy as np\n","n, d = 10, 4\n","X = np.random.rand(n, d)\n","Xc = (X-np.mean(X, axis=0))\n","print(Xc)"]},{"cell_type":"markdown","metadata":{"id":"SCVaPLwhKNcB"},"source":["2. Obtener la matriz de covarianza de $X^T$, revisar en la teoría por qué utilizamos la transpuesta. Buscar en la documentación de NumPy qué funciones se pueden utilizar."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EHy6eWr6KNcC","executionInfo":{"status":"ok","timestamp":1650921860371,"user_tz":180,"elapsed":15,"user":{"displayName":"Benjamin Alfredo Tourn","userId":"09466237909255247827"}},"outputId":"08b5d0e2-fb3e-4c00-9e00-6e1cb9210741"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.08669806 -0.02419624  0.00233144  0.03048566]\n"," [-0.02419624  0.10250784  0.02013602 -0.04758059]\n"," [ 0.00233144  0.02013602  0.09453913 -0.01514082]\n"," [ 0.03048566 -0.04758059 -0.01514082  0.09430064]]\n","[[ 0.08669806 -0.02419624  0.00233144  0.03048566]\n"," [-0.02419624  0.10250784  0.02013602 -0.04758059]\n"," [ 0.00233144  0.02013602  0.09453913 -0.01514082]\n"," [ 0.03048566 -0.04758059 -0.01514082  0.09430064]]\n"]}],"source":["# INSERTAR CÓDIGO AQUÍ\n","covX = np.cov(Xc.T)\n","covX1 = 1/(n-1)*np.dot(Xc.T,Xc)\n","print(covX)\n","print(covX1)"]},{"cell_type":"markdown","metadata":{"id":"-ifQuCO7KNcD"},"source":["3. Calcular los autovalores y autovectores de la matriz de covarianza. Revisar la documentación de NumPy."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SOK7rWuaKNcD","executionInfo":{"status":"ok","timestamp":1650921860827,"user_tz":180,"elapsed":88,"user":{"displayName":"Benjamin Alfredo Tourn","userId":"09466237909255247827"}},"outputId":"c8b50c3b-2431-4f17-b807-ca8df62a5cb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0.17120511 0.09508466 0.06278689 0.04896901]\n","[[ 0.39264812 -0.50458889 -0.71893898 -0.27266141]\n"," [-0.63701711 -0.04951637 -0.52602755  0.56129525]\n"," [-0.27462179 -0.85453086  0.4401292   0.02541985]\n"," [ 0.60383734 -0.11276164  0.11272996  0.78099759]]\n"]}],"source":["# INSERTAR CÓDIGO AQUÍ\n","from numpy import linalg as LA\n","w, v = LA.eig(covX)\n","print(w)\n","print(v)"]},{"cell_type":"markdown","metadata":{"id":"hy_DsYAZKNcE"},"source":["4. Ordernar los autovectores en el sentido de los autovalores decrecientes, revisar la teoría de ser necesario."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kapbd11KNcF","executionInfo":{"status":"ok","timestamp":1650921860831,"user_tz":180,"elapsed":87,"user":{"displayName":"Benjamin Alfredo Tourn","userId":"09466237909255247827"}},"outputId":"2b65fa1a-803e-4fd5-b619-e01b7bb298e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 2 3]\n","[0.17120511 0.09508466 0.06278689 0.04896901]\n","[[ 0.39264812 -0.50458889 -0.71893898 -0.27266141]\n"," [-0.63701711 -0.04951637 -0.52602755  0.56129525]\n"," [-0.27462179 -0.85453086  0.4401292   0.02541985]\n"," [ 0.60383734 -0.11276164  0.11272996  0.78099759]]\n"]}],"source":["# INSERTAR CÓDIGO AQUÍ\n","ava_sort = -np.sort(-w)\n","idx = np.argsort(w)[::-1]\n","print(idx)\n","ave_sort = v[:, idx]\n","print(ava_sort)\n","print(ave_sort)"]},{"cell_type":"markdown","metadata":{"id":"MfbF1AZUKNcG"},"source":["5. Proyectar el dataset centrado sobre los $m$ autovectores más relevantes (Hint: usen np.dot)."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MiWnu0FoKNcG","executionInfo":{"status":"ok","timestamp":1650922616592,"user_tz":180,"elapsed":437,"user":{"displayName":"Benjamin Alfredo Tourn","userId":"09466237909255247827"}},"outputId":"1d3f2675-d1d7-4c35-8e86-a195109e89d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.46113201 -0.36211205 -0.24009843  0.80907862 -0.27109982  0.20298515\n","  -0.02882624 -0.32933801 -0.46116599  0.21944475]\n"," [-0.55742775 -0.2927839   0.2295173   0.07144734  0.40839661  0.09011602\n","   0.14346797 -0.09754548 -0.31105258  0.31586447]]\n"]}],"source":["# INSERTAR CÓDIGO AQUÍ\n","m = 2\n","XcT = Xc.T\n","proy = np.dot(ave_sort[:, :m].T, XcT)\n","print(proy)"]},{"cell_type":"markdown","metadata":{"id":"u3mhXOGLKNcH"},"source":["6. Consolidar los pasos anteriores en una función o clase PCA."]},{"cell_type":"code","execution_count":41,"metadata":{"id":"5P1mAFJUKNcH","executionInfo":{"status":"ok","timestamp":1650923456872,"user_tz":180,"elapsed":7,"user":{"displayName":"Benjamin Alfredo Tourn","userId":"09466237909255247827"}}},"outputs":[],"source":["# INSERTAR CÓDIGO AQUÍ\n","def pca_fun(x, m):\n","  mu = np.mean(x, axis=0)\n","  xc = x-mu\n","  covX = np.cov(xc.T)\n","  w, v = LA.eig(covX)\n","  ava_sort = -np.sort(-w)\n","  idx = np.argsort(w)[::-1]\n","  ave_sort = v[:, idx]\n","  xcT = xc.T\n","  ave_mT = ave_sort[:, :m].T\n","  print(ave_mT)\n","  zn = np.dot(ave_mT, xcT)\n","  znT = zn.T\n","  #print(zn)\n","  xr = np.dot(znT, ave_sort[:, :m].T)\n","  xrec = xr + mu\n","  #print(xr)\n","  return znT, xrec\n","\n","#x=np.random.rand(10,5)\n","#z=pca_fun(x, 2)"]},{"cell_type":"markdown","metadata":{"id":"JFo1fgr1KNcI"},"source":["7. Comparar los resultados obtenidos con el modelo de PCA implementado en Scikit-learn ([ver documentación](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)). Tomar como dataset:\n","\n","$X=\\begin{bmatrix}\n","0.8 & 0.7\\\\\n","0.1 & -0.1\n","\\end{bmatrix}$\n","\n","Se debe reducir a un componente. Verificar los resultados con np.testing.assert_allclose"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJeq0O9-KNcI","executionInfo":{"status":"ok","timestamp":1650923657079,"user_tz":180,"elapsed":305,"user":{"displayName":"Benjamin Alfredo Tourn","userId":"09466237909255247827"}},"outputId":"3c2d9f32-e18e-429e-8150-82a9bf461d76"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.53150729]\n"," [ 0.53150729]]\n","[[-0.65850461 -0.75257669]]\n","[[-0.53150729]\n"," [ 0.53150729]]\n","[[ 0.8  0.7]\n"," [ 0.1 -0.1]]\n"]}],"source":["# INSERTAR CÓDIGO AQUÍ\n","from sklearn.decomposition import PCA\n","X0 = np.array([[0.8, 0.7], [0.1, -0.1]])\n","n_components = 1\n","pca = PCA(n_components)\n","pca.fit(X0)\n","#print(pca.explained_variance_ratio_)\n","#print(pca.singular_values_)\n","#print(pca.components_)\n","pca_sklearn = pca.transform(X0)\n","print(pca_sklearn) \n","\n","z, xr = pca_fun(X0, n_components)\n","print(z)\n","print(xr)\n","np.testing.assert_allclose(pca_sklearn, z)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"PCA en NumPy.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}